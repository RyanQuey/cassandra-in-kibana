# references: https://github.com/thelastpickle/docker-cassandra-bootstrap/blob/master/cassandra/config/filebeat.yml
output:
  logstash:
    enabled: true

    # reference container name given in docker-compose.yml (elk)
    # https://www.elastic.co/guide/en/beats/filebeat/current/logstash-output.html
    hosts: ["elk:5044"]
    timeout: 15

    # Disable ssl for now
    # ssl:
    #   certificate_authorities:
    #     - /etc/pki/tls/certs/logstash-beats.crt

# setup filebeat for kibana
setup: 
  kibana: 
    host: "http://elk:5601"

filebeat:
  inputs:
    # for gc.log.*.current
    # separate since doesn't seem to split on the same ones
    # Also allows for other log lines that should be split to split
    #   example:   
    #   2020-07-06T05:49:59.794+0000: 6.757: Total time for which application threads were stopped: 0.0002487 seconds, Stopping threads took: 0.0000177 seconds
    #   ...
    #   TODO don't apply same tokenizers to this
    - paths:
        - "/var/log/cassandra/gc.log*"
      document_type: cassandra_gc_logs

    - paths:
        # should get system.log, debug.log, gremlin.log, output.log, maybe more depending on their setup
        - "/var/log/cassandra/*.log"
      document_type: cassandra_logs

      # line break only on log level marker, to avoid malformed log lines. 
      multiline:
        pattern: ^TRACE|DEBUG|WARN|INFO|ERROR
        negate: true
        match: after


#================================ Processors =====================================
# Configure processors to enhance or manipulate events generated by the beat.
# Borrowing from https://github.com/Anant/cassandra.toolkit/blob/dev/NodeAnalyzer/FilebeatSetup.MD#filebeatyml-usually-sits-in-etcfilebeat
# Use this web GUI to test: https://dissect-tester.jorgelbg.me/. There is also a CLI version here: https://github.com/jorgelbg/dissect-tester 

processors:
  # ( since we are not using a live host.. these are irrelevant) 
  #- add_host_metadata: ~ 
  #- add_cloud_metadata: ~
  #- add_docker_metadata: ~ 
  #- add_kubernetes_metadata: 
  
#-#------------------------------------ cassandra   
  # note that getting these timestamps correct is important, since if we do not extract these timestamps we only have time when filebeat got the logs, not the event time
  # note that this strips out the milliseconds from timestamp (which was originally after the comma). Is an easy change if we want to though
  # also removes `.class` from the java class and line numbers, for easy reading
  # handles e.g., `INFO  [main] 2020-07-06 05:50:09,721  PluginBean.java:53 - CqlSlowLog plugin is now enabled`
  - dissect:
      tokenizer: "%{loglevel} [%{component}] %{timestamp} %{+timestamp},%{} %{javaclass}.%{}:%{} - %{message}"
      # what we try to tokenize
      field: "message"

      # what we convert it to
      target_prefix: "ingest"

      # even better than adding specific amount of spaces before and after fields in the tokenizer
      # we can be flexible on space amounts but still strip whitespaces from field values
      trim_values: all

  # here we run more processing on the event timestamps we extract (?)
  - timestamp:
      field: "ingest.timestamp"
      layouts:
        - '2006 Jan _2 15:04:05'
        - '2006-01-02 15:04:05'
      test:
        - '2020 Jun  8 02:40:01'
        - '2001 Jan 17 15:04:01'
        - '2019-06-22 16:33:51'
        - '2020-06-13 12:57:30'
      ignore_failure: true
      target_field: "@timestamp"

  - include_fields:
      fields: [ "ingest", "message", "log", "input" ]
